{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038e9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b01155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        y = self.relu1(conv1)\n",
    "        y = self.pool1(y)\n",
    "        conv2 = self.conv2(y)\n",
    "        y = self.relu2(conv2)\n",
    "        y = self.pool2(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.relu4(y)\n",
    "        y = self.fc3(y)\n",
    "        y = self.relu5(y)\n",
    "        return y, conv1, conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f48058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "train_dataset = mnist.MNIST(root='./train', train=True, transform=ToTensor(), download=True)\n",
    "test_dataset = mnist.MNIST(root='./test', train=False, transform=ToTensor(), download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3325d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate training data into each class\n",
    "train_dataset_0 = []\n",
    "train_dataset_1 = []\n",
    "train_dataset_2 = []\n",
    "train_dataset_3 = []\n",
    "train_dataset_4 = []\n",
    "train_dataset_5 = []\n",
    "train_dataset_6 = []\n",
    "train_dataset_7 = []\n",
    "train_dataset_8 = []\n",
    "train_dataset_9 = []\n",
    "for digit in train_dataset:\n",
    "    if(digit[1] == 0):\n",
    "        train_dataset_0.append(digit)\n",
    "    if(digit[1] == 1):\n",
    "        train_dataset_1.append(digit)\n",
    "    if(digit[1] == 2):\n",
    "        train_dataset_2.append(digit)\n",
    "    if(digit[1] == 3):\n",
    "        train_dataset_3.append(digit)\n",
    "    if(digit[1] == 4):\n",
    "        train_dataset_4.append(digit)\n",
    "    if(digit[1] == 5):\n",
    "        train_dataset_5.append(digit)\n",
    "    if(digit[1] == 6):\n",
    "        train_dataset_6.append(digit)\n",
    "    if(digit[1] == 7):\n",
    "        train_dataset_7.append(digit)\n",
    "    if(digit[1] == 8):\n",
    "        train_dataset_8.append(digit)\n",
    "    if(digit[1] == 9):\n",
    "        train_dataset_9.append(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0cf4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate teating data into each class\n",
    "test_dataset_0 = []\n",
    "test_dataset_1 = []\n",
    "test_dataset_2 = []\n",
    "test_dataset_3 = []\n",
    "test_dataset_4 = []\n",
    "test_dataset_5 = []\n",
    "test_dataset_6 = []\n",
    "test_dataset_7 = []\n",
    "test_dataset_8 = []\n",
    "test_dataset_9 = []\n",
    "for digit in test_dataset:\n",
    "    if(digit[1] == 0):\n",
    "        test_dataset_0.append(digit)\n",
    "    if(digit[1] == 1):\n",
    "        test_dataset_1.append(digit)\n",
    "    if(digit[1] == 2):\n",
    "        test_dataset_2.append(digit)\n",
    "    if(digit[1] == 3):\n",
    "        test_dataset_3.append(digit)\n",
    "    if(digit[1] == 4):\n",
    "        test_dataset_4.append(digit)\n",
    "    if(digit[1] == 5):\n",
    "        test_dataset_5.append(digit)\n",
    "    if(digit[1] == 6):\n",
    "        test_dataset_6.append(digit)\n",
    "    if(digit[1] == 7):\n",
    "        test_dataset_7.append(digit)\n",
    "    if(digit[1] == 8):\n",
    "        test_dataset_8.append(digit)\n",
    "    if(digit[1] == 9):\n",
    "        test_dataset_9.append(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f4a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "model = Model()\n",
    "sgd = SGD(model.parameters(), lr=1e-1)\n",
    "cost = CrossEntropyLoss()\n",
    "epoch = 10\n",
    "\n",
    "#feature_maps_conv1 = []\n",
    "#feature_maps_conv2 = []\n",
    "for _epoch in range(epoch):\n",
    "\n",
    "    model.train()\n",
    "    for idx, (train_x, train_label) in enumerate(train_loader):\n",
    "        label_np = np.zeros((train_label.shape[0], 10))\n",
    "        sgd.zero_grad()\n",
    "        predict_y, feature_map_conv_1, feature_map_conv_2 = model(train_x.float())\n",
    "        #predict_y = predict_y.detach()\n",
    "        #feature_maps_conv1.append(feature_map_conv_1)\n",
    "        #feature_maps_conv2.append(feature_map_conv_2)\n",
    "        loss = cost(predict_y, train_label.long())\n",
    "        #if idx % 10 == 0:\n",
    "            #print('idx: {}, loss: {}'.format(idx, loss.sum().item()))\n",
    "        loss.backward()\n",
    "        sgd.step()\n",
    "\n",
    "    #correct = 0\n",
    "    #_sum = 0\n",
    "    #model.eval()\n",
    "    #for idx, (test_x, test_label) in enumerate(test_loader):\n",
    "    #    predict_y, feature_map_conv_1, feature_map_conv_2 = model(test_x.float())\n",
    "    #    predict_y = predict_y.detach()\n",
    "    #    feature_maps_conv1.append(feature_map_conv_1)\n",
    "    #    feature_maps_conv2.append(feature_map_conv_2)\n",
    "    #   predict_ys = np.argmax(predict_y, axis=-1)\n",
    "    #    label_np = test_label.numpy()\n",
    "    #    _ = predict_ys == test_label\n",
    "    #    correct += np.sum(_.numpy(), axis=-1)\n",
    "    #    _sum += _.shape[0]\n",
    "\n",
    "    #print('accuracy: {:.2f}'.format(correct / _sum))\n",
    "    #torch.save(model, 'models/mnist_{:.2f}.pkl'.format(correct / _sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e7d445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModelOnDigit(testing_data):\n",
    "    batch_size = 1\n",
    "    #train_loader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(testing_data, batch_size=batch_size)\n",
    "    model = Model()\n",
    "    sgd = SGD(model.parameters(), lr=1e-1)\n",
    "    cost = CrossEntropyLoss()\n",
    "    epoch = 1\n",
    "\n",
    "    feature_maps_conv1 = []\n",
    "    feature_maps_conv2 = []\n",
    "    for _epoch in range(epoch):\n",
    "\n",
    "        #model.train()\n",
    "        #for idx, (train_x, train_label) in enumerate(train_loader):\n",
    "        #    label_np = np.zeros((train_label.shape[0], 10))\n",
    "        #    sgd.zero_grad()\n",
    "        #    predict_y, feature_map_conv_1, feature_map_conv_2 = model(train_x.float())\n",
    "        #    #predict_y = predict_y.detach()\n",
    "        #    feature_maps_conv1.append(feature_map_conv_1)\n",
    "        #    feature_maps_conv2.append(feature_map_conv_2)\n",
    "        #    loss = cost(predict_y, train_label.long())\n",
    "        #    #if idx % 10 == 0:\n",
    "        #        #print('idx: {}, loss: {}'.format(idx, loss.sum().item()))\n",
    "        #    loss.backward()\n",
    "        #    sgd.step()\n",
    "\n",
    "        correct = 0\n",
    "        _sum = 0\n",
    "        model.eval()\n",
    "        for idx, (test_x, test_label) in enumerate(test_loader):\n",
    "            predict_y, feature_map_conv_1, feature_map_conv_2 = model(test_x.float())\n",
    "            predict_y = predict_y.detach()\n",
    "            feature_maps_conv1.append(feature_map_conv_1)\n",
    "            feature_maps_conv2.append(feature_map_conv_2)\n",
    "            predict_ys = np.argmax(predict_y, axis=-1)\n",
    "            label_np = test_label.numpy()\n",
    "            _ = predict_ys == test_label\n",
    "            correct += np.sum(_.numpy(), axis=-1)\n",
    "            _sum += _.shape[0]\n",
    "\n",
    "        #print('accuracy: {:.2f}'.format(correct / _sum))\n",
    "        #torch.save(model, 'models/mnist_{:.2f}.pkl'.format(correct / _sum))\n",
    "    first = 0\n",
    "    last = len(feature_maps_conv1)-1\n",
    "    print(len(feature_maps_conv1))\n",
    "    print(feature_maps_conv2[0].size())\n",
    "    return feature_maps_conv1, feature_maps_conv2, first, last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5023ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeFeatureMap(feature_map):\n",
    "    img = np.squeeze(feature_map)\n",
    "\n",
    "    fig = plt.figure(figsize = (24,24)) \n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img.detach().numpy(), cmap='gray')\n",
    "    width, height = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            #val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "            val = img[x][y].item() if img[x][y].item() !=0 else 0\n",
    "            ax.annotate(str(val), xy=(y,x),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color='white' if img[x][y]<thresh else 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4572e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph(feature_map):\n",
    "    pixels= []\n",
    "\n",
    "    img = np.squeeze(feature_map)\n",
    "    width, height = img.shape\n",
    "    print(\"Width: \", width)\n",
    "    print(\"Height: \", height)\n",
    "    thresh = img.max()/2.5\n",
    "    #count = 0\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            #val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "            val = img[x][y].item() if img[x][y].item() !=0 else 0\n",
    "            coord = (x,y)\n",
    "            pixel_tuple = (coord, val)\n",
    "            pixels.append(pixel_tuple)\n",
    "\n",
    "    print(\"\\nDone processing pixel values\\n\")\n",
    "    \n",
    "    #array of tuples, (tuple of coordinate, pixel value)\n",
    "    #sort by descending order, grab top 10%\n",
    "    print(\"Total number of pixels: \", len(pixels))\n",
    "    desc_pixels = sorted(pixels, key = lambda x: x[1], reverse = True)\n",
    "    num_pixels = len(desc_pixels)\n",
    "    top10 = round(num_pixels/10)\n",
    "    top10per_pixels = desc_pixels[0:top10]\n",
    "    print(\"Top 10%: \", len(top10per_pixels), \"pixels\")\n",
    "    #make nodes\n",
    "    coords = set()\n",
    "    G = nx.Graph()\n",
    "    for pixel in top10per_pixels:\n",
    "        G.add_node(pixel[0])\n",
    "        coords.add(pixel[0])\n",
    "\n",
    "    print(\"Nodes in graph: \", len(G.nodes))\n",
    "    print(\"Nodes in set: \", len(coords))\n",
    "    #scan through and add edges if nodes are adjacent\n",
    "    for pixel in top10per_pixels:\n",
    "        coord = pixel[0]\n",
    "        #North\n",
    "        if((coord[0],coord[1]-1) in coords):\n",
    "            G.add_edge(coord, (coord[0],coord[1]-1))\n",
    "        #East\n",
    "        if((coord[0]+1,coord[1]) in coords):\n",
    "            G.add_edge(coord, (coord[0]+1,coord[1]))\n",
    "        #South\n",
    "        if((coord[0],coord[1]+1) in coords):\n",
    "            G.add_edge(coord, (coord[0],coord[1]+1))\n",
    "        #West\n",
    "        if((coord[0]-1,coord[1]) in coords):\n",
    "            G.add_edge(coord, (coord[0]-1,coord[1]))\n",
    "\n",
    "    print(\"Edges in graph: \", len(G.edges))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01fc2bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892\n",
      "torch.Size([1, 16, 8, 8])\n",
      "Width:  8\n",
      "Height:  8\n",
      "\n",
      "Done processing pixel values\n",
      "\n",
      "Total number of pixels:  64\n",
      "Top 10%:  6 pixels\n",
      "Nodes in graph:  6\n",
      "Nodes in set:  6\n",
      "Edges in graph:  2\n"
     ]
    }
   ],
   "source": [
    "#Testing the functions\n",
    "#trainModelOnDigit passes in all the training data of a single digitand returns the feature maps and indices of the first and last\n",
    "feature_maps_conv1, feature_maps_conv2, first, last = testModelOnDigit(test_dataset_5)\n",
    "\n",
    "#uncomment next line to see feature map on grid\n",
    "#visualizeFeatureMap(feature_maps_conv2[last][0][0])\n",
    "\n",
    "#createGraph takes in a feature map and creates the graph of top 10%\n",
    "G = createGraph(feature_maps_conv2[last][0][0])\n",
    "\n",
    "#Export graph to gephi\n",
    "nx.write_gexf(G, \"conv2_trained_5.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359ff63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5923\n",
      "torch.Size([1, 16, 8, 8])\n",
      "Width:  24\n",
      "Height:  24\n",
      "\n",
      "Done processing pixel values\n",
      "\n",
      "Total number of pixels:  576\n",
      "Top 10%:  58 pixels\n",
      "Nodes in graph:  58\n",
      "Nodes in set:  58\n",
      "Edges in graph:  41\n",
      "Width:  24\n",
      "Height:  24\n",
      "\n",
      "Done processing pixel values\n",
      "\n",
      "Total number of pixels:  576\n",
      "Top 10%:  58 pixels\n",
      "Nodes in graph:  58\n",
      "Nodes in set:  58\n",
      "Edges in graph:  52\n",
      "Width:  8\n",
      "Height:  8\n",
      "\n",
      "Done processing pixel values\n",
      "\n",
      "Total number of pixels:  64\n",
      "Top 10%:  6 pixels\n",
      "Nodes in graph:  6\n",
      "Nodes in set:  6\n",
      "Edges in graph:  1\n",
      "Width:  8\n",
      "Height:  8\n",
      "\n",
      "Done processing pixel values\n",
      "\n",
      "Total number of pixels:  64\n",
      "Top 10%:  6 pixels\n",
      "Nodes in graph:  6\n",
      "Nodes in set:  6\n",
      "Edges in graph:  1\n"
     ]
    }
   ],
   "source": [
    "# Create graphs for untrained and trained versions of every digit class\n",
    "\n",
    "#Class digit 0\n",
    "#Just change the input dataset from train_dataset_0 to train_dataset_x where x is the digit you want to train\n",
    "#Two levels on convolution, first layer has more pixels(look at output)\n",
    "#First layer is 24x24\n",
    "#Second layer is only 8x8\n",
    "feature_maps_conv1, feature_maps_conv2, first, last = testModelOnDigit(train_dataset_0)\n",
    "Gconv1_untrained_0 = createGraph(feature_maps_conv1[first][0][0])\n",
    "#visualizeFeatureMap(feature_maps_conv1[first][0][0])\n",
    "Gconv1_trained_0 = createGraph(feature_maps_conv1[last][0][0])\n",
    "#visualizeFeatureMap(feature_maps_conv1[last][0][0])\n",
    "Gconv2_untrained_0 = createGraph(feature_maps_conv2[first][0][0])\n",
    "#visualizeFeatureMap(feature_maps_conv2[first][0][0])\n",
    "Gconv2_trained_0 = createGraph(feature_maps_conv2[last][0][0])\n",
    "#visualizeFeatureMap(feature_maps_conv2[last][0][0])\n",
    "nx.write_gexf(Gconv1_untrained_0, \"conv1_untrained_0.gexf\")\n",
    "nx.write_gexf(Gconv1_trained_0, \"conv1_trained_0.gexf\")\n",
    "nx.write_gexf(Gconv2_untrained_0, \"conv2_untrained_0.gexf\")\n",
    "nx.write_gexf(Gconv2_trained_0, \"conv2_trained_0.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2fd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
